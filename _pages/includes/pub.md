
# ğŸ“ Publications 
## ä¸€ä½œ/å…±ä¸€è®ºæ–‡(7)
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv 2025</div><img src='images/EviNoteRAG_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[arXiv25][EviNote-RAG: Enhancing RAG Models via Answer-Supportive Evidence Notes](https://arxiv.org/abs/2509.00877)
 
<a href="https://github.com/Da1yuqin/EviNoteRAG"><img src="https://img.shields.io/github/stars/Da1yuqin/EviNoteRAG?style=social" alt="GitHub Stars" /></a>
<a href="https://github.com/Da1yuqin/EviNoteRAG"><img src="https://img.shields.io/github/forks/Da1yuqin/EviNoteRAG?style=social" alt="GitHub Forks" /></a>
[[Github]](https://github.com/Da1yuqin/EviNoteRAG)
[[æœºå™¨ä¹‹å¿ƒ]](https://mp.weixin.qq.com/s/FOo38trc3OSEx2EXqVwyFA)

**Yuqin Dai**\*, Guoqing Wang\*, Yuan Wang\*, Kairan Dou, Kaichen Zhou, Zhanwei Zhang, Shuo Yang, Fei Tang, Jun Yin, Pengyu Zeng, Zhenzhe Ying, Can Yi, Changhua Meng, Yuchen Zhou, Yongliang Shen, Shuai Lu

- æˆ‘ä»¬æå‡º EviNote-RAG æ¡†æ¶ï¼Œå°†â€œæ£€ç´¢-å›ç­”â€æ¨¡å¼æ”¹ä¸ºâ€œæ£€ç´¢-ç¬”è®°-å›ç­”â€ï¼Œæå‡ä¿¡æ¯æç‚¼å’Œæ¨ç†å¯é æ€§ã€‚
- å¼•å…¥ç±»äººç±»çš„æ£€ç´¢å¼æ‘˜è¦æœºåˆ¶ï¼Œç”Ÿæˆæ”¯æŒæ€§è¯æ®ç¬”è®°ï¼ˆSENsï¼‰ï¼Œçªå‡ºå…³é”®ä¿¡æ¯å’Œä¸ç¡®å®šç‚¹ï¼Œå‡å°‘å™ªéŸ³ã€æå‡èšç„¦ã€‚
- æ–¹æ³•åœ¨å¤šä¸ªé—®ç­”åŸºå‡†ä¸Šè¾¾åˆ° SOTAï¼Œä¸ä»…æ•ˆæœæ˜¾è‘—æå‡ï¼Œè¿˜å¤§å¹…å¢å¼ºè®­ç»ƒç¨³å®šæ€§å’Œæ•ˆç‡ï¼Œä¾‹å¦‚åœ¨ HotpotQAã€Bamboogleã€2Wiki ä¸Šåˆ†åˆ«æå‡ F1 20% (+0.093)ã€40% (+0.151)ã€91% (+0.256)ã€‚
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2026</div><img src='images/WebFilter_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[AAAI26][Careful Queries, Credible Results: Teaching RAG Models Advanced Web Search Tools with Reinforcement Learning](https://arxiv.org/pdf/2508.07956)
 
<a href="https://github.com/GuoqingWang1/WebFilter"><img src="https://img.shields.io/github/stars/GuoqingWang1/WebFilter?style=social" alt="GitHub Stars" /></a>
<a href="https://github.com/GuoqingWang1/WebFilter"><img src="https://img.shields.io/github/forks/GuoqingWang1/WebFilter?style=social" alt="GitHub Forks" /></a>
[[Github]](https://github.com/GuoqingWang1/WebFilter)

 **Yuqin Dai**\*, Shuo Yang\*, Guoqing Wang\*, Yong Deng, Zhanwei Zhang, Jun Yin, Pengyu Zeng, Zhenzhe Ying, Changhua Meng, Can Yi, Yuchen Zhou, Weiqiang Wang, Shuai Lu
- æˆ‘ä»¬æå‡ºäº† WebFilter æ¡†æ¶ï¼Œå°†æ£€ç´¢è¿‡ç¨‹å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ä½¿ç”¨é«˜çº§ç½‘é¡µæœç´¢æ“ä½œç¬¦ï¼Œä»è€Œåœ¨çœŸå®ç½‘ç»œç¯å¢ƒä¸­æœ‰æ•ˆè¿‡æ»¤è™šå‡ä¿¡æ¯ã€‚
- è®¾è®¡äº†ä¿¡æ¯è¿‡æ»¤å¥–åŠ±ç­–ç•¥ï¼Œç»“åˆâ€œæ¥æºé™åˆ¶å¥–åŠ±â€å’Œâ€œæ£€ç´¢ç²¾åº¦å¥–åŠ±â€ï¼ŒåŒæ—¶ä¼˜åŒ–æŸ¥è¯¢è¡Œä¸ºä¸æ£€ç´¢ç»“æœè´¨é‡ï¼Œæ˜¾è‘—æé«˜äº†æ£€ç´¢ç²¾å‡†åº¦ä¸å¯ä¿¡åº¦ã€‚
- å®éªŒè¡¨æ˜ï¼ŒWebFilter åœ¨å¤šé¡¹é—®ç­”åŸºå‡†ä¸Šå–å¾—äº†æœ€ä¼˜æ€§èƒ½ï¼Œé«˜çº§æœç´¢æ“ä½œç¬¦çš„ä½¿ç”¨ç‡ç”± 10% æå‡è‡³ 75%ï¼Œå¹¶åœ¨åŸŸå†…ä¸è·¨åŸŸä»»åŠ¡ä¸­å‡å±•ç°å‡ºå¼ºæ³›åŒ–èƒ½åŠ›ã€‚
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv 2025</div><img src='images/TCDiffpp_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[arXiv][TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography](https://arxiv.org/pdf/2506.18671)
 
<a href="https://github.com/Da1yuqin/TCDiffpp"><img src="https://img.shields.io/github/stars/Da1yuqin/TCDiffpp?style=social" alt="GitHub Stars" /></a>
<a href="https://github.com/Da1yuqin/TCDiffpp"><img src="https://img.shields.io/github/forks/Da1yuqin/TCDiffpp?style=social" alt="GitHub Forks" /></a>
[[Github]](https://github.com/Da1yuqin/TCDiffpp) [[Project Page]](https://da1yuqin.github.io/TCDiffpp.website/)

 **Yuqin Dai**\*, Wanlu Zhu\*, Ronghui Li, Xiu Li, Zhenyu Zhang, Jun Li,Jian Yang
- æˆ‘ä»¬æå‡ºTCDiff++, ä¸€ç§ç«¯åˆ°ç«¯ç‰ˆæœ¬çš„ç¾¤èˆç”Ÿæˆæ¨¡å‹ã€‚
- æˆ‘ä»¬å¼•å…¥ä½ç½®åµŒå…¥å’Œä¸€è‡´æ€§æŸå¤±ï¼Œé˜²æ­¢ç¢°æ’å¹¶ä¿æŒåˆç†é—´è·ã€‚
- æ¨¡å‹åŠ å…¥æ¢ä½ä¿¡æ¯å’Œè„šæ­¥è‡ªé€‚åº”å™¨ï¼Œå‡å°‘è„šæ»‘å¹¶æå‡ä¸€è‡´æ€§ã€‚
- ä¼˜åŒ–é•¿æ—¶ç”Ÿæˆæ•ˆæœï¼Œæå‡ºé•¿åºåˆ—é‡‡æ ·ä¸è§£ç å™¨ï¼Œä¼˜åŒ–é•¿èˆè¹ˆç”Ÿæˆçš„è¿è´¯æ€§ã€‚
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='images/mindaligner_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[ICML25][MindAligner: Explicit Brain Functional Alignment for Cross-Subject Visual Decoding from Limited fMRI Data](https://arxiv.org/pdf/2502.05034)
 
<a href="https://github.com/Da1yuqin/MindAligner"><img src="https://img.shields.io/github/stars/Da1yuqin/MindAligner?style=social" alt="GitHub Stars" /></a>
<a href="https://github.com/Da1yuqin/MindAligner"><img src="https://img.shields.io/github/forks/Da1yuqin/MindAligner?style=social" alt="GitHub Forks" /></a>
[[Github]](https://github.com/Da1yuqin/TCDiff) 
 
**Yuqin Dai**\*, Zhouheng Yao\*, Chunfeng Song, Qihao Zheng, Weijian Mai, Kunyu Peng, Shuai Lu, Wanli Ouyang, Jian Yang, Jiamin Wu.
- æˆ‘ä»¬æå‡ºäº†MindAlignerï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ˜¾å¼çš„å¤§è„‘å¯¹é½æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹å®ç°è·¨ä¸ªä½“çš„è§†è§‰è§£ç å’Œå¤§è„‘åŠŸèƒ½åˆ†æã€‚
- æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤§è„‘è½¬ç§»çŸ©é˜µï¼Œç”¨äºå»ºç«‹ä¸åŒä¸ªä½“ä¹‹é—´çš„ç»†ç²’åº¦åŠŸèƒ½å¯¹åº”å…³ç³»ã€‚è¯¥çŸ©é˜µé€šè¿‡å¤§è„‘åŠŸèƒ½å¯¹é½æ¨¡å—è¿›è¡Œä¼˜åŒ–ï¼Œé‡‡ç”¨å¤šå±‚æ¬¡å¯¹é½æŸå¤±å®ç°è½¯æ€§è·¨ä¸ªä½“æ˜ å°„ã€‚
- å®éªŒè¡¨æ˜ï¼ŒMindAligneråœ¨è§†è§‰è§£ç ä»»åŠ¡ä¸­ï¼Œåªæœ‰6%çš„æ¨¡å‹å‚æ•°è¢«å­¦ä¹ æ—¶ï¼Œä¾¿è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚
- æˆ‘ä»¬è¿›è¡Œäº†è·¨ä¸ªä½“çš„å¤§è„‘åŠŸèƒ½å¯è§†åŒ–ç ”ç©¶ï¼Œå‘ç°æ—©æœŸè§†è§‰çš®å±‚åœ¨ä¸åŒä¸ªä½“é—´æ´»åŠ¨ç›¸ä¼¼ï¼Œè€Œä¸è®°å¿†å’Œç©ºé—´å¯¼èˆªç›¸å…³çš„é«˜çº§è§†è§‰çš®å±‚åˆ™è¡¨ç°å‡ºæ˜¾è‘—çš„ä¸ªä½“é—´å·®å¼‚ã€‚
</div>
</div>




<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI2025 OralğŸ¥‡</div><img src='images/TCDiff_mainfig.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[AAAI25 Oral][Harmonious Group Choreography with Trajectory-Controllable Diffusion](https://arxiv.org/pdf/2403.06189)

<a href="https://github.com/Da1yuqin/TCDiff"><img src="https://img.shields.io/github/stars/Da1yuqin/TCDiff?style=social" alt="GitHub Stars" /></a>
<a href="https://github.com/Da1yuqin/TCDiff"><img src="https://img.shields.io/github/forks/Da1yuqin/TCDiff?style=social" alt="GitHub Forks" /></a>
[[Github]](https://github.com/Da1yuqin/TCDiff) [[Project Page]](https://wanluzhu.github.io/TCDiffusion/)

__Yuqin Dai__, Wanlu Zhu, Ronghui Li, Zeping Ren, Xiangzheng Zhou, Xiu Li, Jun Li, Jian Yang. 
- å‘ç°å¹¶æå‡ºé¢†åŸŸå†…å­˜åœ¨çš„é—®é¢˜: èˆè€…æ··æ·†(Dancer Ambiguity)ç°è±¡. ä¸ºåç»­ç ”ç©¶æä¾›æŒ‡å¼•ä¸æ€è·¯. 
- TCDiff æ˜¯å½“å‰ SOTA çš„å¤šäººèˆè¹ˆç”Ÿæˆæ¨¡å‹, èƒ½å¤Ÿè¾ƒå¥½çš„è§£å†³èˆè€…æ··æ·†(Dancer Ambiguity)ç°è±¡.
- æå‡ºäº† Footwork Adaptor æ¨¡å—, èƒ½æœ‰æ•ˆç¼“è§£å¤šäººèˆè¹ˆç”Ÿæˆä¸­çš„è„šæ­¥æ»‘åŠ¨é—®é¢˜(Foot Slide).
- æå‡ºäº† Fusion Projection æ’ä»¶, è¯¥æ’ä»¶å ç”¨è¾ƒå°çš„è®¡ç®—èµ„æº, èƒ½å¤Ÿæœ‰æ•ˆè§£å†³èˆè€…æ··æ·†(Dancer Ambiguity)ç°è±¡

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP2024 OralğŸ¥‡</div><img src='images/mainfig_text2avatar.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[ICASSP24 Oral][Text2Avatar: Text to 3D Human Avatar Generation with Codebook-Driven Body Controllable Attribute](https://ieeexplore.ieee.org/document/10446237)

 Chaoqun Gong\*, __Yuqin Dai__\*, Ronghui Li, Achun Bao, Jun Li, Jian Yang, Yachao Zhang, Xiu L. 
- Text2Avatar æ˜¯ç¬¬ä¸€ä¸ªåŸºäºå¤æ‚è€¦åˆçš„è¾“å…¥æ–‡æœ¬æç¤ºç”Ÿæˆé€¼çœŸé£æ ¼çš„ 3D Avatar çš„æ¨¡å‹ï¼Œå®ç°äº†å¤šå±æ€§å¯æ§å’Œé€¼çœŸçš„ 3D äººå¤´åƒç”Ÿæˆã€‚
- Text2Avatar æ¨¡å‹åŸºäº 3D-Aware GAN(NeRF-Based), ä½¿ç”¨ GAN-Inversion based çš„æ–¹å¼å®ç°æ–‡æœ¬å¯¹é½, å·§å¦™åŒ–è§£äº†å½“å‰æ–‡æœ¬æ ‡æ³¨çš„å†™å®é£æ ¼ä¸‰ç»´ Avatar æ•°æ®é›†ç¼ºå¤±çš„é—®é¢˜.
- æå‡º Multi-Modal Encoder, èƒ½å¤Ÿä½œä¸ºæ’ä»¶æœåŠ¡äºå…¶ä»–æ¨¡å‹, å…·æœ‰å¾ˆå¼ºçš„å¯æ‰©å±•æ€§.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP2024</div><img src='images/DanceControl_mainfig.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[ICASSP24][EXPLORING MULTI-MODAL CONTROL IN MUSIC-DRIVEN DANCE GENERATION](https://ieeexplore.ieee.org/document/10447825)

Ronghui Li\*, __Yuqin Dai__\*, Yachao Zhang, Jun Li, Jian Yang, Jie Guo, Xiu Li. 
- æå‡ºäº†ç¬¬ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„èˆè¹ˆåŠ¨ä½œï¼Œå¹¶æ”¯æŒå¤šæ¨¡æ€æ§åˆ¶ï¼ŒåŒ…æ‹¬åŒæ—¶è¿›è¡Œæµæ´¾æ§åˆ¶ã€è¯­ä¹‰æ§åˆ¶å’Œç©ºé—´æ§åˆ¶ã€‚
- æ¨¡å‹èƒ½å¤Ÿè¿›è¡ŒéŸ³ä¹è·¨æ¨¡æ€èˆè¹ˆç”Ÿæˆ(Music2Dance), åŸºäº VQ-GPT æ¶æ„, èƒ½å¤Ÿä¸€æ¬¡ç”Ÿæˆé•¿è¾¾ 16s çš„èˆè¹ˆåŠ¨ä½œ, å¹¶èƒ½é€šè¿‡è‡ªå›å½’çš„æ–¹å¼å¯¹ç”Ÿæˆå†…å®¹è¿›è¡Œæ‹“å±•. 

</div>
</div>

## å‚ä¸å·¥ä½œï¼ˆ9ï¼‰
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2026 OralğŸ‘‘</div><img src='images/logic_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[AAAI26][Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models](https://arxiv.org/pdf/2508.11317)

Yuchen Zhou, Jiayu Tang, Shuo Yang, Xiaoyan Xiao, **Yuqin Dai**, Wenhao Yang, Chao Gou, Xiaobo Xia, Tat-Seng Chua
- æå‡º LogicBench åŸºå‡†ï¼šæ„å»ºäº†ä¸€ä¸ªæ¶µç›– 9 ç±»é€»è¾‘å…³ç³»ã€4 ç§åº”ç”¨åœºæ™¯å’Œ 2 ç§è¯„æµ‹ä»»åŠ¡çš„ç»¼åˆåŸºå‡†ï¼ŒåŒ…å«è¶…è¿‡ 5 ä¸‡å¯¹é€»è¾‘è§†è§‰-è¯­è¨€æ ·æœ¬ï¼Œç”¨äºç³»ç»Ÿæ€§è¯„ä¼°å¤šæ¨¡æ€å¤§æ¨¡å‹çš„é€»è¾‘ç†è§£èƒ½åŠ›ã€‚
- å¼€å±•ç³»ç»Ÿæ€§è¯Šæ–­è¯„æµ‹ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§åˆ†æå¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨é€»è¾‘æ¨ç†æ–¹é¢çš„è¡¨ç°ï¼Œæ­ç¤ºäº†å…¶åœ¨ç†è§£å¤æ‚é€»è¾‘ç»“æ„æ—¶å­˜åœ¨çš„æ˜¾è‘—â€œé€»è¾‘ç›²ç‚¹â€å’Œå›ºæœ‰é™åˆ¶ã€‚
- æå‡º LogicCLIP æ¡†æ¶ï¼šè®¾è®¡äº†ä¸€ç§æ–°å‹è®­ç»ƒæ–¹æ³•ï¼Œæœ‰æ•ˆå¢å¼ºæ¨¡å‹çš„é€»è¾‘æ•æ„Ÿæ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒLogicCLIP åœ¨å¤šä¸ªé¢†åŸŸæ˜¾è‘—æå‡é€»è¾‘ç†è§£èƒ½åŠ›çš„åŒæ—¶ï¼Œè¿˜ä¿æŒç”šè‡³è¶…è¶Šäº†åœ¨æ ‡å‡†è§†è§‰-è¯­è¨€åŸºå‡†ä¸Šçš„è¡¨ç°ã€‚
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2025</div><img src='images/card_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[EMNLP25][Card: Cross-modal agent framework for generative and editable residential design](https://aclanthology.org/2025.emnlp-main.473.pdf)

Pengyu Zeng, Jun Yin, Miao Zhang, **Yuqin Dai**, Jizhizi Li, ZhanXiang Jin, Shuai Lu
- æå‡º CARD è·¨æ¨¡æ€ä½å®…è®¾è®¡æ¡†æ¶ï¼Œå¯ä»è‡ªç„¶è¯­è¨€ç”Ÿæˆå¹¶ç¼–è¾‘ä½å®…å¸ƒå±€ã€‚
- è®¾è®¡ CMI-P è·¨æ¨¡æ€ç©ºé—´è¡¨ç¤ºä¸ Text2FloorEdit ç”Ÿæˆæ¨¡å‹ï¼Œå®ç°æ ‡å‡†åŒ–ä¸å¯è¿­ä»£è®¾è®¡ã€‚
- æ„å»ºåŒ…å«è§„èŒƒå®¡æŸ¥ã€éœ€æ±‚éªŒè¯ä¸ 3D å¯è§†åŒ–çš„å¤šä»£ç†ç³»ç»Ÿï¼Œæ”¯æŒæ™®é€šç”¨æˆ·æ— ä¸“ä¸šèƒŒæ™¯è¿›è¡Œä½å®…è®¾è®¡ã€‚
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv 2025</div><img src='images/atom_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[arXiv25][Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward](https://arxiv.org/pdf/2508.12800)

<a href="https://github.com/antgroup/Research-Venus"><img src="https://img.shields.io/github/stars/antgroup/Research-Venus?style=social" alt="GitHub Stars" /></a>
<a href="https://github.com/antgroup/Research-Venus"><img src="https://img.shields.io/github/forks/antgroup/Research-Venus?style=social" alt="GitHub Forks" /></a>
[[Github]](https://github.com/antgroup/Research-Venus) 
[[æœºå™¨ä¹‹å¿ƒ]](https://zhuanlan.zhihu.com/p/1944058738945291292)

Yong Dengâˆ—, Guoqing Wangâˆ—, Zhenzhe Yingâˆ—, Xiaofeng Wuâˆ—, Jinzhen Lin, Wenwen Xiong, **Yuqin Dai**, Shuo Yang, Zhanwei Zhang, Qiwen Wang, Yang Qin, Changhua Meng
- æå‡ºå…¨æ–°çš„â€œåŸå­æ€ç»´â€èŒƒå¼ï¼šå°†å¤§æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹æ‹†è§£ä¸ºç»†ç²’åº¦çš„åŠŸèƒ½å•å…ƒï¼Œä»è€Œå¼•å¯¼æ¨¡å‹è¿›è¡Œæ›´æ¸…æ™°ã€æ›´æ·±å…¥çš„æ¨ç†ã€‚
- è®¾è®¡åŸå­æ€ç»´å¥–åŠ±æœºåˆ¶ï¼ˆATRï¼‰åŠè¯¾ç¨‹å¼èšåˆç­–ç•¥ï¼šé€šè¿‡å°† ATR ä¸æœ€ç»ˆç»“æœå¥–åŠ±ç»“åˆï¼Œç¼“è§£äº†ç­–ç•¥ä¼˜åŒ–ä¸­çš„æ¢¯åº¦å†²çªå’Œå¥–åŠ±ç¨€ç–é—®é¢˜ã€‚
- æ„å»º Atom-Searcher æ¡†æ¶å¹¶éªŒè¯æ•ˆæœï¼šåŸºäºåŸå­æ€ç»´ä¸å¥–åŠ±èšåˆç­–ç•¥ï¼Œæå‡ºäº†ä¸€ä¸ªæ–°çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ Atom-Searcherï¼Œåœ¨ä¸ƒä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¶…è¶Šç°æœ‰æœ€ä¼˜æ–¹æ³•ï¼Œå¹¶å±•ç°å‡ºå¤šæ–¹é¢ä¼˜åŠ¿ã€‚
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2025 OralğŸ‘‘</div><img src='images/logic_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[ACM MM25][MRED-14: A Benchmark for Low-Energy Residential Floor Plan Generation with 14 Flexible Inputs](https://dl.acm.org/doi/pdf/10.1145/3746027.3754949)

Pengyu Zeng, Jun Yin, Haoyuan Sun, **Yuqin Dai**, Maowei Jiang, Miao Zhang, Shuai Lu
- æ„å»ºé¦–ä¸ªåŒ…å«14ç§è¾“å…¥ç±»å‹çš„å¤šæ¨¡æ€ä½å®…èƒ½è€—æ•°æ®é›† MRED-14ã€‚
- æå‡ºå¯çµæ´»é€‚é…å¤šè¾“å…¥çš„ä½èƒ½è€—æˆ·å‹ç”Ÿæˆæ¨¡å‹ LER-netã€‚
- å®éªŒéªŒè¯æ¨¡å‹èƒ½é™ä½æˆ·å‹èƒ½è€—å¹¶ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·æœ‰å®é™…è®¾è®¡å¯è¡Œæ€§ã€‚
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv 2025</div><img src='images/RAMA_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[arXiv25][RAMA: Retrieval-Augmented Multi-Agent Framework for Misinformation Detection in Multimodal Fact-Checking](https://arxiv.org/pdf/2507.09174?)
 
<a href="https://github.com/kalendsyang/RAMA"><img src="https://img.shields.io/github/stars/kalendsyang/RAMA?style=social" alt="GitHub Stars" /></a>
<a href="https://github.com/kalendsyang/RAMA"><img src="https://img.shields.io/github/forks/kalendsyang/RAMA?style=social" alt="GitHub Forks" /></a>
[[Github]](https://github.com/kalendsyang/RAMA) 

Shuo Yang, Zijian Yu, Zhenzhe Ying, **Yuqin Dai**, Guoqing Wang, Jun Lan, Jinfeng Xu, Jinze Li, Edith C.H. Ngai
- æå‡ºäº†ä¸€ä¸ªå¤šæ¨¡æ€èåˆæ¡†æ¶ï¼Œå°†è§†è§‰ç‰¹å¾ä¸è¯­è¨€æ¨¡å‹æœ‰æ•ˆç»“åˆï¼Œå®ç°è·¨æ¨¡æ€æ¨ç†ä¸ç”Ÿæˆèƒ½åŠ›çš„æ˜¾è‘—æå‡ã€‚
- å¼•å…¥åŠ¨æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡è‡ªé€‚åº”åœ°è°ƒæ•´è§†è§‰ä¸æ–‡æœ¬ä¿¡æ¯çš„æƒé‡ï¼Œä»è€Œæå‡äº†æ¨¡å‹åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­çš„é²æ£’æ€§ä¸æ³›åŒ–æ€§ã€‚
- åœ¨å¤šé¡¹å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ï¼ˆå¦‚å›¾æ–‡åŒ¹é…ã€è§†è§‰é—®ç­”ç­‰ï¼‰ä¸­ï¼Œè¯¥æ–¹æ³•å‡å–å¾—äº†ä¼˜äºç°æœ‰æ–¹æ³•çš„æ€§èƒ½è¡¨ç°ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ä¸å…ˆè¿›æ€§ã€‚
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACMMM25 Datasets</div><img src='images/realfactbentch_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[ACMMM25 Datasets][RealFactBench: A Benchmark for Evaluating Large Language Models in Real-World Fact-Checking](https://arxiv.org/pdf/2506.12538)
 
<a href="https://github.com/kalendsyang/RealFactBench"><img src="https://img.shields.io/github/stars/kalendsyang/RealFactBench?style=social" alt="GitHub Stars" /></a>
<a href="https://github.com/Dkalendsyang/RealFactBench"><img src="https://img.shields.io/github/forks/kalendsyang/RealFactBench?style=social" alt="GitHub Forks" /></a>
[[Github]](https://github.com/kalendsyang/RealFactBench) 
 
Shuo Yang, **Yuqin Dai**, Guoqing Wang, Xinran Zheng, Jinfeng Xu, Jinze Li, Zhenzhe Ying, Weiqiang Wang, Edith CH Ngai.
- æˆ‘ä»¬æå‡º RealFactBench åŸºå‡†æµ‹è¯•é›†ï¼šæ„å»ºäº†ä¸€ä¸ªæ¶µç›–çŸ¥è¯†éªŒè¯ã€è°£è¨€æ£€æµ‹å’Œäº‹ä»¶æ ¸æŸ¥ç­‰å¤šç§çœŸå®ä¸–ç•Œä»»åŠ¡çš„ç»¼åˆæ€§åŸºå‡†ï¼Œç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMsï¼‰çš„äº‹å®æ ¸æŸ¥èƒ½åŠ›ã€‚
- å¼•å…¥æ–°çš„è¯„ä¼°æŒ‡æ ‡ Unknown Rate (UnR)ï¼šè¯¥æŒ‡æ ‡ç”¨äºæ›´ç»†è‡´åœ°è¡¡é‡æ¨¡å‹åœ¨ä¸ç¡®å®šæ€§å¤„ç†æ–¹é¢çš„è¡¨ç°ï¼Œå¸®åŠ©è¯„ä¼°æ¨¡å‹åœ¨ä¿å®ˆæ€§ä¸è‡ªä¿¡ç¨‹åº¦ä¹‹é—´çš„å¹³è¡¡ã€‚
- å¼€å±•å¤§è§„æ¨¡å®è¯ç ”ç©¶ï¼šåœ¨7ä¸ªå…¸å‹LLMså’Œ4ä¸ªMLLMsä¸Šè¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨äº‹å®æ ¸æŸ¥ä»»åŠ¡ä¸­çš„å±€é™æ€§ï¼Œå¹¶ä¸ºåç»­ç ”ç©¶æä¾›äº†æœ‰ä»·å€¼çš„æ´å¯Ÿã€‚
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TPAMI 2025</div><img src='images/hvsurvey_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[TPAMI25][Human Motion Video Generation: A Survey](https://www.techrxiv.org/users/836049/articles/1228135-human-motion-video-generation-a-survey)

<a href="https://github.com/Winn1y/Awesome-Human-Motion-Video-Generation?tab=readme-ov-file"><img src="https://img.shields.io/github/stars/Winn1y/Awesome-Human-Motion-Video-Generation?style=social" alt="GitHub Stars" /></a>
<a href="https://github.com/Winn1y/Awesome-Human-Motion-Video-Generation?tab=readme-ov-file"><img src="https://img.shields.io/github/forks/Winn1y/Awesome-Human-Motion-Video-Generation?style=social" alt="GitHub Forks" /></a>
[[Github]](https://github.com/Winn1y/Awesome-Human-Motion-Video-Generation?tab=readme-ov-file) [[Project Page]](https://github.com/Winn1y/Awesome-Human-Motion-Video-Generation?tab=readme-ov-file)

Haiwei Xue,Xiangyang Luo,Zhanghao Hu,Xin Zhang,Xunzhi Xiang,__Yuqin Dai__,Jianzhuang Liu,Zhensong Zhang,Minglei Li,Jian Yang,Fei Ma,Zhiyong Wu,Changpeng Yang,Zonghong Dai,Fei Richard Yu. 
- æ•°å­—äººè§†é¢‘ç”Ÿæˆé¢†åŸŸç»¼è¿°. 
- æ€»ç»“äº†è¶…è¿‡300ç¯‡æœ€æ–°æ•°å­—äººè§†é¢‘ç”Ÿæˆäº†é¢†åŸŸç›¸å…³æ–‡çŒ®çš„å†…å®¹.
- æ€»ç»“äº†ç°æœ‰æ•°å­—äººè§†é¢‘ç”Ÿæˆé¢†åŸŸèŒƒå¼.

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL25 OralğŸ¥‡, SAC Highlightsâ­</div><img src='images/FloorPlan-LLaMa_mainfig.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[ACL25 Oral][FloorPlan-LLaMa: Aligning Architectsâ€™ Feedback and Domain Knowledge in Architectural Floor Plan Generation](https://aclanthology.org/2025.acl-long.331/)

<a href="https://github.com/TsinghuaJunYin/FloorPlan-LLaMa"><img src="https://img.shields.io/github/stars/TsinghuaJunYin/FloorPlan-LLaMa?style=social" alt="GitHub Stars" /></a>
<a href="https://github.com/TsinghuaJunYin/FloorPlan-LLaMa"><img src="https://img.shields.io/github/forks/TsinghuaJunYin/FloorPlan-LLaMa?style=social" alt="GitHub Forks" /></a>
[[Github]](https://github.com/TsinghuaJunYin/FloorPlan-LLaMa) 
[[æ–°æ™ºå…ƒ]](https://mp.weixin.qq.com/s/bmfeBXVqOn4e6NvQOdkklw)

Jun Yin, Pengyu Zeng, Haoyuan Sun, **Yuqin Dai**, Han Zheng, Miao Zhang, Yachao Zhang, Shuai Lu
- æå‡ºäº†ArchiMetricsNetæ•°æ®é›†ä¸FloorPlan-MPSè¯„ä»·æ¨¡å‹ï¼šé¦–æ¬¡æ„å»ºäº†ä¸€ä¸ªåŒ…å«åŠŸèƒ½æ€§ã€æµçº¿æ€§å’Œæ•´ä½“æ€§è¯„ä¼°å¾—åˆ†çš„æ¥¼é¢å›¾æ•°æ®é›†ï¼Œå¹¶é…æœ‰è¯¦ç»†çš„æ–‡æœ¬åˆ†æï¼Œç”¨ä»¥æ›´è´´è¿‘å»ºç­‘ä¸“ä¸šçŸ¥è¯†åœ°è¯„ä¼°ç”Ÿæˆç»“æœã€‚
- å¼€å‘äº†FloorPlan-LLaMaç”Ÿæˆæ¨¡å‹å¹¶å¼•å…¥RLHFæœºåˆ¶ï¼šè®¾è®¡äº†åŸºäºè‡ªå›å½’æ¡†æ¶çš„æ¥¼é¢å›¾ç”Ÿæˆæ¨¡å‹FloorPlan-LLaMaï¼Œå¹¶é€šè¿‡å¼•å…¥FloorPlan-MPSä½œä¸ºå¥–åŠ±æ¨¡å‹ï¼Œå€ŸåŠ©äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰æœºåˆ¶ä½¿æ¨¡å‹æ›´ç¬¦åˆå»ºç­‘å¸ˆçš„ä¸“ä¸šåå¥½ã€‚
- å®éªŒè¯æ˜æ–¹æ³•ä¼˜äºç°æœ‰åŸºçº¿å¹¶è·ä¸“ä¸šè®¤å¯ï¼šåœ¨æ–‡æœ¬æ¡ä»¶å’Œç±»åˆ«æ¡ä»¶çš„ç”Ÿæˆä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œä¸”ç»ä¸“ä¸šå»ºç­‘å¸ˆéªŒè¯ï¼Œå…¶ç”Ÿæˆç»“æœæ›´ä¸ºåˆç†ï¼Œå¥‘åˆäººç±»è®¾è®¡åå¥½ã€‚
</div>
</div>


<!-- 
## ä¸­æ–‡è®ºæ–‡
[åŸºäºEncoder-Decoderæ³¨æ„åŠ›ç½‘ç»œçš„å¼‚å¸¸é©¾é©¶è¡Œä¸ºåœ¨çº¿è¯†åˆ«æ–¹æ³•](http://bzxb.cqut.edu.cn/paperinfo.aspx?paperid=11163)ï¼Œå…µå™¨è£…å¤‡å·¥ç¨‹å­¦æŠ¥2023(æ ¸å¿ƒæœŸåˆŠ) 
- å”å¤(æŒ‡å¯¼è€å¸ˆ)ï¼Œ__æˆ´è¯­ç´__ï¼Œå¾æ°¸èƒ½ï¼Œéƒ­å”ä»ªï¼Œé‚µé£
- æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå®æ—¶ç›‘æ§é©¾é©¶å‘˜å¼‚å¸¸é©¾é©¶è¡Œä¸ºçš„æ¡†æ¶ã€‚ä¸ç°æœ‰ä¾èµ–å¤§é‡æ˜‚è´µé«˜ç²¾åº¦ä¼ æ„Ÿå™¨çš„æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬åªä½¿ç”¨æ‰‹æœºæ•°æ®è¿›è¡Œå¼‚å¸¸é©¾é©¶è¡Œä¸ºæ£€æµ‹ï¼Œä½¿æˆ‘ä»¬çš„æ–¹æ³•æ›´åŠ å®ç”¨ã€‚

[è½¬åŠ¨æƒ¯é‡å¹³è¡Œè½´å®šç†éªŒè¯å®éªŒçš„æ”¹è¿›æ–¹æ¡ˆ](https://dxwl.bnu.edu.cn/CN/10.16854%20/j.cnki.1000-0712.190392)ï¼Œå¤§å­¦ç‰©ç†2020(æ ¸å¿ƒæœŸåˆŠ)
- é—«æ•ï¼Œ__æˆ´è¯­ç´__ï¼Œè¢ä¿Šï¼Œç‹æ™“é›„
- æˆ‘ä»¬æ‰¾åˆ°äº†ä¸€ç§æ¯”ç›®å‰çš„æ•™å­¦æ–¹æ³•æ›´å‡†ç¡®çš„æ–¹æ³•ï¼Œå¯ä»¥æ˜¾ç€å‡å°‘å®éªŒä¸­æµ‹é‡åˆšä½“è½¬åŠ¨æƒ¯é‡æ—¶å¼•å…¥çš„è¯¯å·®é‡ã€‚è¿™å°†æœ‰åŠ©äºå¤§å­¦ç”Ÿæ›´æœ‰æ•ˆåœ°è¿›è¡Œå®éªŒï¼Œæ›´å¥½åœ°ç†è§£å®éªŒåŸç†ã€‚



## ä¸“åˆ©
- å”å¤ï¼Œ æ¨åŠ›ï¼Œ __æˆ´è¯­ç´__ï¼Œéƒ­å”ä»ªï¼Œå¾æ°¸èƒ½. [åŸºäºç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›ç½‘ç»œå’ŒLSTMçš„å¼‚å¸¸é©¾é©¶åœ¨çº¿è¯†åˆ«æ–¹æ³•](https://xueshu.baidu.com/usercenter/paper/show?paperid=180r0c70ap6800w0hu2t0jn0je340821#:~:text=%E5%BC%82%E5%B8%B8%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E6%98%AF%E8%BD%A6%E8%BE%86%E5%AE%89%E5%85%A8%E8%BF%90%E8%A1%8C%E7%9A%84%E9%87%8D%E5%A4%A7%E5%A8%81%E8%83%81%2C%E5%85%B6%E5%AF%B9%E4%BA%BA%E5%91%98%E4%B8%8E%E7%89%A9%E8%B5%84%E7%9A%84%E5%AE%89%E5%85%A8%E9%AB%98%E6%95%88%E6%8A%95%E9%80%81%E9%80%A0%E6%88%90%E4%B8%A5%E9%87%8D%E5%8D%B1%E5%AE%B3.%E4%BB%A5%E4%BD%8E%E6%88%90%E6%9C%AC%E9%9D%9E%E6%8E%A5%E8%A7%A6%E5%BC%8F%E7%9A%84%E6%89%8B%E6%9C%BA%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E6%95%B0%E6%8D%AE%E4%B8%BA%E5%9F%BA%E7%A1%80%2C%E9%80%9A%E8%BF%87%E5%AF%B9%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E7%89%B9%E6%80%A7%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2C%E6%8F%90%E5%87%BA%E4%B8%80%E7%A7%8D%E8%9E%8D%E5%90%88Encoder-Decoder%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E4%B8%8EAt-tention%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BC%82%E5%B8%B8%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E7%9A%84%E5%9C%A8%E7%BA%BF%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95.%E8%AF%A5%E6%96%B9%E6%B3%95%E7%94%B1%E5%9F%BA%E4%BA%8ELSTM%20%28long%20short-term%20memory%29%E7%9A%84Encoder-Decoder%2CAt-tention%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%9F%BA%E4%BA%8ESVM%20%28support%20vector,machine%29%E7%9A%84%E5%88%86%E7%B1%BB%E5%99%A83%20%E4%B8%AA%E6%A8%A1%E5%9D%97%E6%9E%84%E6%88%90.%E8%AF%A5%E7%B3%BB%E7%BB%9F%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E5%8C%85%E6%8B%AC%3A%E8%BE%93%E5%85%A5%E7%BC%96%E7%A0%81%2C%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%AD%A6%E4%B9%A0%2C%E7%89%B9%E5%BE%81%E8%A7%A3%E7%A0%81%2C%E5%BA%8F%E5%88%97%E9%87%8D%E6%9E%84%2C%E6%AE%8B%E5%B7%AE%E8%AE%A1%E7%AE%97%E4%B8%8E%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E5%88%86%E7%B1%BB%E7%AD%896%20%E4%B8%AA%E6%AD%A5%E9%AA%A4.%E8%AF%A5%E6%8A%80%E6%9C%AF%E6%96%B9%E6%B3%95%E5%88%A9%E7%94%A8%E8%87%AA%E7%84%B6%E9%A9%BE%E9%A9%B6%E6%9D%A1%E4%BB%B6%E4%B8%8B%E6%89%80%E9%87%87%E9%9B%86%E7%9A%84%E6%89%8B%E6%9C%BA%E4%BC%A0%E6%84%9F%E5%99%A8%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%AE%9E%E9%AA%8C.%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E8%A1%A8%E6%98%8E%3A%E2%91%A0%20%E6%89%8B%E6%9C%BA%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88%E6%96%B9%E6%B3%95%E5%AF%B9%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E8%AF%86%E5%88%AB%E5%85%B7%E5%A4%87%E6%9C%89%E6%95%88%E6%80%A7%3B%E2%91%A1%20%E5%BC%82%E5%B8%B8%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E5%BF%85%E7%84%B6%E4%BC%9A%E9%80%A0%E6%88%90%E6%95%B0%E6%8D%AE%E5%BC%82%E5%B8%B8%E6%B3%A2%E5%8A%A8%3B%E2%91%A2%20Attention%E6%9C%BA%E5%88%B6%E6%9C%89%E5%8A%A9%E4%BA%8E%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E6%95%88%E6%9E%9C%2C%E5%AF%B9%E6%89%80%E6%8F%90%E5%87%BA%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%86%E5%88%AB%E5%87%86%E7%A1%AE%E7%8E%87F1-score%E4%B8%BA0.717%2C%E4%B8%8E%E7%BB%8F%E5%85%B8%E5%90%8C%E7%B1%BB%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83%2C%E5%87%86%E7%A1%AE%E7%8E%87%E5%BE%97%E5%88%B0%E6%98%BE%E8%91%97%E6%8F%90%E5%8D%87%3B%E2%91%A3%E5%AF%B9%E4%BA%8E%E6%B1%BD%E8%BD%A6%E5%BC%82%E5%B8%B8%E9%A9%BE%E9%A9%B6%E8%A1%8C%E4%B8%BA%E6%9D%A5%E8%AF%B4%2CSVM%E6%AF%94Logistic%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%AE%97%E6%B3%95%E5%85%B7%E6%9C%89%E6%9B%B4%E4%BC%98%E8%B6%8A%E7%9A%84%E8%AF%86%E5%88%AB%E6%95%88%E6%9E%9C.). ç”³è¯·ç¼–å·ï¼ˆä¸“åˆ©å·ï¼‰ï¼šCN202111675120.8 åº”ç”¨æ—¥æœŸï¼š2021-12-31), Pengfei Wei, Lingdong Kong, Xinghua Qu, **Yi Ren**, et al.
-->

